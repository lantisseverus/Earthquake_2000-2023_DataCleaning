Earthquake 2000-2023 Data Cleaning
================

## Motivation

As an East Asian, I can never forget living in an area which
unfortunately on the seismic belt. I cannot resonate more when seeing
the tragedies in Turkey and Syria right now. 3.11 Japan Touhoku
Earthquake just had its 12th anniversary and now the same natural
disaster stroke Turkey. It’s a great opportunity to review the history
that we human beings deal with earthquakes.

My data analysis will dedicate to answering the following questions: \*
Where are earthquakes frequently take place between 2000 and 2023? \*
What are the top 5 strong magnitudes and their Focal Depth (km)of the
earthquake between 2000 and 2023? \* By comparing the death and injured
people in each earthquake to discuss if any other external factors can
mitigate the impact. \* By comparing the Damage to discuss if these
damages can be prevented by intervening beforehand.

Hope those who are unfortunately deceased can rest in peace and the data
can bring some insights into future prevention and preparation.

## Import Data

This dataset came from Kaggle Dataset: *Earthquakes -2150 BC – 2023 AD
around the world* Link:
<https://www.kaggle.com/datasets/bharathposa/earthquakes-from-2150bc-2023-ad-around-the-world>.

I will use `readr` package (which is a package of `tidyverse`) to read
the csv file. And then use glimpse function to take a quick review of
this data.

``` r
earthquake_df = read_csv("earthquakes.csv")
```

    ## Rows: 6350 Columns: 38
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr  (1): Location Name
    ## dbl (37): Year, Mo, Dy, Hr, Mn, Sec, Tsu, Vol, Latitude, Longitude, Focal De...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
glimpse(earthquake_df)
```

    ## Rows: 6,350
    ## Columns: 38
    ## $ Year                                 <dbl> NA, -2150, -2000, -2000, -1610, -…
    ## $ Mo                                   <dbl> NA, NA, NA, NA, NA, NA, NA, NA, N…
    ## $ Dy                                   <dbl> NA, NA, NA, NA, NA, NA, NA, NA, N…
    ## $ Hr                                   <dbl> NA, NA, NA, NA, NA, NA, NA, NA, N…
    ## $ Mn                                   <dbl> NA, NA, NA, NA, NA, NA, NA, NA, N…
    ## $ Sec                                  <dbl> NA, 0, NA, NA, NA, 0, NA, NA, 0, …
    ## $ Tsu                                  <dbl> NA, NA, 1, NA, 3, NA, NA, 4, NA, …
    ## $ Vol                                  <dbl> NA, NA, NA, NA, 1351, NA, NA, NA,…
    ## $ `Location Name`                      <chr> NA, "JORDAN:  BAB-A-DARAA,AL-KARA…
    ## $ Latitude                             <dbl> NA, 31.100, 35.683, 38.000, 36.40…
    ## $ Longitude                            <dbl> NA, 35.50, 35.80, 58.20, 25.40, 3…
    ## $ `Focal Depth (km)`                   <dbl> NA, NA, NA, 18, NA, NA, NA, NA, N…
    ## $ Mag                                  <dbl> NA, 7.3, NA, 7.1, NA, NA, NA, NA,…
    ## $ `MMI Int`                            <dbl> NA, NA, 10, 10, NA, 10, 10, NA, N…
    ## $ Deaths                               <dbl> NA, NA, NA, 1, NA, NA, NA, NA, NA…
    ## $ `Death Description`                  <dbl> NA, NA, 3, 1, NA, NA, NA, NA, NA,…
    ## $ Missing                              <dbl> NA, NA, NA, NA, NA, NA, NA, NA, N…
    ## $ `Missing Description`                <dbl> NA, NA, NA, NA, NA, NA, NA, NA, N…
    ## $ Injuries                             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, N…
    ## $ `Injuries Description`               <dbl> NA, NA, NA, NA, NA, NA, NA, NA, N…
    ## $ `Damage ($Mil)`                      <dbl> NA, NA, NA, NA, NA, NA, NA, NA, N…
    ## $ `Damage Description`                 <dbl> NA, 3, NA, 1, NA, 3, NA, 3, 3, 3,…
    ## $ `Houses Destroyed`                   <dbl> NA, NA, NA, NA, NA, NA, NA, NA, N…
    ## $ `Houses Destroyed Description`       <dbl> NA, NA, NA, 1, NA, NA, NA, NA, NA…
    ## $ `Houses Damaged`                     <dbl> NA, NA, NA, NA, NA, NA, NA, NA, N…
    ## $ `Houses Damaged Description`         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, N…
    ## $ `Total Deaths`                       <dbl> NA, NA, NA, 1, NA, NA, NA, NA, NA…
    ## $ `Total Death Description`            <dbl> NA, NA, 3, 1, 3, NA, NA, NA, NA, …
    ## $ `Total Missing`                      <dbl> NA, NA, NA, NA, NA, NA, NA, NA, N…
    ## $ `Total Missing Description`          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, N…
    ## $ `Total Injuries`                     <dbl> NA, NA, NA, NA, NA, NA, NA, NA, N…
    ## $ `Total Injuries Description`         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, N…
    ## $ `Total Damage ($Mil)`                <dbl> NA, NA, NA, NA, NA, NA, NA, NA, N…
    ## $ `Total Damage Description`           <dbl> NA, NA, NA, 1, 3, NA, NA, 3, NA, …
    ## $ `Total Houses Destroyed`             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, N…
    ## $ `Total Houses Destroyed Description` <dbl> NA, NA, NA, 1, NA, NA, NA, NA, NA…
    ## $ `Total Houses Damaged`               <dbl> NA, NA, NA, NA, NA, NA, NA, NA, N…
    ## $ `Total Houses Damaged Description`   <dbl> NA, NA, NA, NA, NA, NA, NA, NA, N…

## Data Cleaning

We now understand the data and the data types of each column. Let’s get
our hand dirty with data cleaning! What I am going to do with the data
cleaning:

1.  Concatenate the year, month, and day as a Date column.  
2.  I will apply the filter on the data to subset only data from 2000 to
    2023.
3.  Select only the columns that are relevant to my questions of
    interest.

``` r
earthquake_df %>% mutate(date = make_date(year = Year, month = Mo, day = Dy)) %>%  filter(date >= "2000-01-01" & date <= "2023-12-31") %>% select(date, `Location Name`, Latitude, Longitude, `Focal Depth (km)`, Mag, Deaths, Injuries, `Damage ($Mil)`,`Houses Damaged`, `Total Deaths`, `Total Injuries`, `Total Damage ($Mil)`, `Total Houses Damaged`)
```

    ## # A tibble: 1,298 × 14
    ##    date       Location Na…¹ Latit…² Longi…³ Focal…⁴   Mag Deaths Injur…⁵ Damag…⁶
    ##    <date>     <chr>           <dbl>   <dbl>   <dbl> <dbl>  <dbl>   <dbl>   <dbl>
    ##  1 2000-01-03 INDIA-BANGLA…   22.1     92.8      33   4.6     NA      NA    NA  
    ##  2 2000-01-11 CHINA:  LIAO…   40.5    123.       10   5.1     NA      30    NA  
    ##  3 2000-01-14 CHINA:  YUNN…   25.6    101.       33   5.9      5    2528    73.5
    ##  4 2000-02-02 IRAN:  BARDA…   35.3     58.2      33   5.3      1      15    NA  
    ##  5 2000-02-07 SOUTH AFRICA…  -26.3     30.9       5   4.5     NA       1    NA  
    ##  6 2000-03-28 JAPAN:  VOLC…   22.3    144.      127   7.6     NA      NA    NA  
    ##  7 2000-04-05 GREECE:  CRE…   34.2     25.7      38   5.5     NA      NA    NA  
    ##  8 2000-05-04 INDONESIA:  …   -1.10   124.       26   7.6     54     264    30  
    ##  9 2000-05-07 TURKEY:  DOG…   38.2     38.8       5   4.1     NA      NA    NA  
    ## 10 2000-05-17 TAIWAN:  TAI…   24.2    121.       10   5.4      3      13    NA  
    ## # … with 1,288 more rows, 5 more variables: `Houses Damaged` <dbl>,
    ## #   `Total Deaths` <dbl>, `Total Injuries` <dbl>, `Total Damage ($Mil)` <dbl>,
    ## #   `Total Houses Damaged` <dbl>, and abbreviated variable names
    ## #   ¹​`Location Name`, ²​Latitude, ³​Longitude, ⁴​`Focal Depth (km)`, ⁵​Injuries,
    ## #   ⁶​`Damage ($Mil)`
