---
title: "Earthquake 2000-2023 Data Cleaning"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

## Motivation


As an East Asian, I can never forget living in an area which unfortunately on the seismic belt. I cannot resonate more when seeing the tragedies in Turkey and Syria right now. 3.11 Japan Touhoku Earthquake just had its 12th anniversary and now the same natural disaster stroke Turkey. It's a great opportunity to review the history that we human beings deal with earthquakes. 

My data analysis will dedicate to answering the following questions:

-  Where are earthquakes frequently take place between 2000 and 2023?
-  What are the top 5 strong magnitudes and their Focal Depth (km)of the earthquake between 2000 and 2023?
- By comparing the casualties and magnitude of each earthquake to discuss if any other external factors can mitigate the impact.
- By comparing the Damage and House Destroyed with the magnitude of each quake to discuss if these damages can be prevented by intervening beforehand.

Hope those who are unfortunately deceased can rest in peace and the data can bring some insights into future prevention and preparation. 


## Import Data

This dataset came from Kaggle Dataset: *Earthquakes -2150 BC -- 2023 AD around the world* Link: https://www.kaggle.com/datasets/bharathposa/earthquakes-from-2150bc-2023-ad-around-the-world.

I will use `readr` package (which is a package of `tidyverse`) to read the csv file. And then use glimpse function to take a quick review of this data. 

```{r import data, echo=FALSE}
earthquake_df = read_csv("earthquakes.csv")
glimpse(earthquake_df)
```

## Data Cleaning

We now understand the data and the data types of each column. Let's get our hand dirty with data cleaning! What I am going to do with the data cleaning: 

1. Concatenate the year, month, and day as a Date column.  
2. I will apply the filter on the data to subset only data from 2000 to 2023. 
3. Select only the columns that are relevant to my questions of interest.
4. Rename the variable to make its naming more consistent
5. Create 2 new variables to estimate the overall impact on human beings

```{r data cleaning }
filtered_df = earthquake_df %>% mutate(date = make_date(year = Year, month = Mo, day = Dy)) %>%  filter(date >= "2000-01-01" & date <= "2023-12-31") %>% select(date, `Location Name`, Latitude, Longitude, `Focal Depth (km)`, Mag, Deaths, Injuries, `Damage ($Mil)`,`Houses Damaged`, `Total Deaths`, `Total Injuries`, `Total Damage ($Mil)`, `Total Houses Damaged`) %>% rename(location = `Location Name`, 
           Depth_km = `Focal Depth (km)`,
           Damage_Mil = `Damage ($Mil)`,
           House_Damaged = `Houses Damaged`,
           Total_Death = `Total Deaths`,
           Total_Injuries = `Total Injuries`,
           Total_Damage_Mil = `Total Damage ($Mil)`, 
           Total_House_Damaged = `Total Houses Damaged`
           ) %>% 
  mutate(Casualty = Deaths + Injuries, 
         Total_Casualty = Total_Death + Total_Injuries)


```
From Step 1 to 5, we have 1298 entries of observation, but most of the data containing `NA` values. 

I decide to take further step to remove those incompleted cases. 

6. Remove records with `NA` or null value

```{r remove NA}
cleaned_earthquake_df = na.omit(filtered_df) 

cleaned_earthquake_df %>% head() %>%  knitr::kable()
```

After filtering and removing the `NA` values from the data, we have only 55 observations. 

## Data Processing

We can still rank the top 5 strongest Earthquake from the data.

```{r}
cleaned_earthquake_df %>% 
  arrange(-Mag) %>% 
  select(date, location, Mag, Depth_km) %>% 
  head(5) %>% 
  knitr::kable()
```
We know that the top 5 earthquakes so far took place between 2000 and 2023 are:

1. Japan Touhoku Earthquake 9.1
2. Chile Maule, Concepcion, Talcahuano Earthquake 8.8
3. Chile Central Earthquake 8.3
4. Mexico: Oaxaca, Chiapas, Tabasco; Guatemala 8.3
5. China Sichuan Earthquake 7.9

The focal depth of 4 out of 5 earthquakes reside 10-30 km.

Next, I want to find which country has the most earthquakes between 2000 and 2023.
To do this, I need to separate the location name into country name and location name. 

To make the country names and location more readable, I will modify its font.
```{r Separate Country from Locaton Name, warning=FALSE}
country_cleaned_df = cleaned_earthquake_df %>% separate(location,c("country", "location"), ":") %>% mutate(country = tools::toTitleCase(tolower(country)), 
                                                                                          location = tools::toTitleCase(tolower(location)))
```

```{r}
country_cleaned_df %>% group_by(country) %>% summarize(frequency = n()) %>% arrange(-frequency) %>% head(5) %>% knitr::kable()
```
From the result, we can see that most of the earthquakes took place in East and Southeast Asia - including China, Japan, Philippines, Indonesia, India. A few earthquake also took place in Central and South America, such as Chile, Haiti, and Mexico. 

The top 4 countries* will be:

1. China
2. Japan
3. Philippines
4. Indonesia 

*NOTE: Choosing top 4 instead of top 5 because the fifth place has the same frequency as the rest (i.e., 6th to 10th place).

## Dig into the context behind the casulty

Let's dig into the number behind the casualty.
First, I notice that for each record, there are deaths and total deaths; injuries and total injuries. These pair-wise variables also lead to the creation of casualty and total casualty. Not sure how to distinguish these similar variables.

After simple comparison, most of the data are in alignment with death - total death, injuries - total injuries, and casualty - total casualty. Only these 3 records are in difference. 
```{r Casulty Statistics}
country_cleaned_df %>% 
  group_by(country) %>% 
  summarize(sum_death = sum(Deaths),
            sum_t_death = sum(Total_Death),
            sum_injured = sum(Injuries),
            sum_t_injured = sum(Total_Injuries), 
            sum_casualty = sum(Casualty), 
            sum_t_casualty = sum(Total_Casualty)) %>% 
  filter(sum_death != sum_t_death | sum_injured != sum_t_injured | sum_casualty != sum_t_casualty) %>% knitr::kable()
```

To define the casualty, I tend to be lenient toward the numbers. Hence, I decide to use the total casualty as an indicator since I believe it includes the direct and indirect casualties from the disaster. 

##### My original hypothesis is: The bigger the magnitude, the more casualty the disaster caused.

```{r Casualty Arregation}
country_cleaned_df %>% group_by(date, country, Mag) %>% summarize(Max_casualty = max(Total_Casualty)) %>% arrange(-Max_casualty) %>% head(5)
```
However, from the above table, we can see that Japan has the strongest magnitude earthquake between 2000 to 2023. The casualties are not the worst. We may infer from the result that magnitude is not the only factor that caused casualties but infrastructure and familiarity with massive emergency first aid.

Let's use a graph to present the hypothesis with the data.
```{r Casualy Viz}
country_cleaned_df %>% group_by(date, country, Mag) %>% summarize(Max_casualty = max(Total_Casualty)) %>% ggplot(aes(x = Mag, y = Max_casualty)) + geom_point() + geom_smooth()+ scale_y_continuous(labels = scales::unit_format(unit = "M", scale = 1e-6)) + labs(title = "Max Casualty and Magnitude of Earthquake") +
  xlab("Magnitude") + ylab("Max Casualty (Million)")
```
We can see the scatter plot and the smooth line are almost horizontally related, which meant they are barely relevant. But, before drawing a conclusion, let's test it with a correlation test.

```{r Preleminary test }
casualty_df = country_cleaned_df %>% group_by(date, country, Mag) %>% summarize(Max_casualty = max(Total_Casualty)) 
shapiro.test(casualty_df$Mag)
shapiro.test(casualty_df$Max_casualty)
```
From the output, the two p-values are greater than the significance level 0.05 implying that the distribution of the data are not significantly different from normal distribution. In other words, we can assume the normality.

```{r  Casualty Mag Cor Test}
res = cor.test(casualty_df$Mag, casualty_df$Max_casualty, 
                    method = "pearson")
res
```
The correlation coefficient: 0.1764589 is close to 0 meaning that there is no association between the two variables (Magnitude and Casualty).

## Deep Dive into the Damage and the House Destroyed of each quake

Again, I notice that for each record, there are Damage in Million and Total Damage in Million; House Damaged and Total House Damaged.Not sure how to distinguish these similar variables.

After simple comparison, most of the data are in alignment with death - total death, injuries - total injuries, and casualty - total casualty. Only these 2 records are in difference. 

```{r Damage Statistics}
country_cleaned_df %>% 
  group_by(country) %>% 
  summarize(sum_damage_mil = sum(Damage_Mil),
            sum_t_damage_mil = sum(Total_Damage_Mil),
            sum_house_damaged = sum(House_Damaged),
            sum_t_house_damaged = sum(Total_House_Damaged)) %>% 
  filter(sum_damage_mil != sum_t_damage_mil | sum_house_damaged != sum_t_house_damaged) %>% knitr::kable()
```

To define the Damage, I again incline to be lenient toward the numbers. Hence, I decide to use the Total Damage in Million and Total House Damaged as 2 indicators since I believe they include the direct and indirect damages from the disaster. 

##### My original hypothesis is The bigger the magnitude, the more damage the disaster caused and the more houses damaged by the disaster.

```{r Damage and house damage overview}
country_cleaned_df %>% group_by(date, country, Mag) %>% summarize(sum_damage = sum(Total_Damage_Mil), 
          sum_house_damage = sum(Total_House_Damaged)) %>% arrange(desc(sum_damage), desc(sum_house_damage)) %>% head(5) %>% knitr::kable()
```
From the above table, we can see that Japan has the strongest magnitude earthquake between 2000 to 2023. The damage cost the most but the amount of the house damaged is not the most. The damage and house damaged should be treated separately in this case.

Since house damage may include other factors such as the building materials. 

Let's visualize the relationship between Total Damage in Million and Magnitude.

```{r Damage in Mil and Magnitude Viz}
country_cleaned_df %>% group_by(date, country, Mag) %>% summarize(sum_damage = sum(Total_Damage_Mil)) %>% ggplot(aes(x = Mag, y = sum_damage)) + geom_point() + geom_smooth()+ geom_vline(xintercept = 8, colour="red", linetype = "longdash") + labs(title = "The Relationship between sum of Damage in Million and Magnitude of Earthquake") +
  xlab("Magnitude") + ylab("Sum of Damage (Million)")
```
Interestingly, we found an elbow point in the trend. When the Magnitude of the quake is greater than or equal to 8 the potential damage could range from 1 to 200,000 Million.
